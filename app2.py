import os
import streamlit as st
from dotenv import load_dotenv
from langchain.chat_models import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage
from langchain.chains import LLMChain
from langchain.prompts import ChatPromptTemplate

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

# LLMã®åˆæœŸåŒ–
chat = ChatOpenAI(openai_api_key=openai_api_key, temperature=0.7, model="gpt-3.5-turbo")

# å°‚é–€å®¶ã®æŒ¯ã‚‹èˆã„ã‚’å®šç¾©
expert_roles = {
    "æ „é¤Šå£«": "ã‚ãªãŸã¯å„ªç§€ãªæ „é¤Šå£«ã§ã™ã€‚é£Ÿäº‹ã‚„å¥åº·ã«é–¢ã™ã‚‹è³ªå•ã«å°‚é–€çš„ã«ç­”ãˆã¦ãã ã•ã„ã€‚",
    "æ—…è¡Œãƒ—ãƒ©ãƒ³ãƒŠãƒ¼": "ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªæ—…è¡Œãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã§ã™ã€‚æ—…è¡Œã®è¨ˆç”»ã‚„ãŠã™ã™ã‚ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚",
    "ã‚­ãƒ£ãƒªã‚¢ã‚³ãƒ¼ãƒ": "ã‚ãªãŸã¯ä¿¡é ¼ã§ãã‚‹ã‚­ãƒ£ãƒªã‚¢ã‚³ãƒ¼ãƒã§ã™ã€‚ä»•äº‹ã‚„è»¢è·ã€ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—ã«ã¤ã„ã¦åŠ©è¨€ã—ã¦ãã ã•ã„ã€‚"
}

# LLMã«å•ã„åˆã‚ã›ã‚‹é–¢æ•°
def get_llm_response(user_input: str, expert_type: str) -> str:
    system_message = SystemMessage(content=expert_roles.get(expert_type, "ã‚ãªãŸã¯å„ªç§€ãªå°‚é–€å®¶ã§ã™ã€‚"))
    human_message = HumanMessage(content=user_input)
    response = chat([system_message, human_message])
    return response.content

# Streamlit UI
st.set_page_config(page_title="LLMå°‚é–€å®¶ã‚¢ãƒ—ãƒª", layout="centered")

st.title("ğŸ§  LLMå°‚é–€å®¶ã‚¢ãƒ—ãƒª")
st.markdown("""
ã“ã®ã‚¢ãƒ—ãƒªã¯ã€OpenAIã®LLMï¼ˆå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰ã‚’æ´»ç”¨ã—ã¦ã€é¸æŠã—ãŸå°‚é–€å®¶ã®è¦–ç‚¹ã‹ã‚‰ã‚ãªãŸã®è³ªå•ã«ç­”ãˆã¾ã™ã€‚  
ä»¥ä¸‹ã®æ‰‹é †ã§ã”åˆ©ç”¨ãã ã•ã„ï¼š

1. å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸æŠã—ã¦ãã ã•ã„  
2. è³ªå•ã‚„ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„  
3. ã€Œé€ä¿¡ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨ã€å°‚é–€å®¶ã‹ã‚‰ã®å›ç­”ãŒè¡¨ç¤ºã•ã‚Œã¾ã™
""")

# ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§å°‚é–€å®¶é¸æŠ
expert_type = st.radio("å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸ã‚“ã§ãã ã•ã„ï¼š", list(expert_roles.keys()))

# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
user_input = st.text_area("è³ªå•ãƒ»ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š", height=150)

# é€ä¿¡ãƒœã‚¿ãƒ³
if st.button("é€ä¿¡"):
    if user_input.strip() == "":
        st.warning("è³ªå•å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("å°‚é–€å®¶ãŒå›ç­”ä¸­ã§ã™..."):
            response = get_llm_response(user_input, expert_type)
            st.success("å°‚é–€å®¶ã‹ã‚‰ã®å›ç­”ï¼š")
            st.write(response)