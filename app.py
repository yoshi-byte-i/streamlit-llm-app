import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage
import os

# Streamlit Secretsã‹ã‚‰APIã‚­ãƒ¼å–å¾—
os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]

# LLMåˆæœŸåŒ–
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.5)

# å°‚é–€å®¶ã®ç¨®é¡
expert_options = {
    "A: æ „é¤Šå­¦ã®å°‚é–€å®¶": "ã‚ãªãŸã¯æ „é¤Šå­¦ã®å°‚é–€å®¶ã§ã™ã€‚å¥åº·çš„ãªé£Ÿäº‹ã‚„æ „é¤Šãƒãƒ©ãƒ³ã‚¹ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
    "B: ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ã®å°‚é–€å®¶": "ã‚ãªãŸã¯ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ã®å°‚é–€å®¶ã§ã™ã€‚é‹å‹•ç¿’æ…£ã‚„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ–¹æ³•ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
    "C: ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ˜ãƒ«ã‚¹ã®å°‚é–€å®¶": "ã‚ãªãŸã¯ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ˜ãƒ«ã‚¹ã®å°‚é–€å®¶ã§ã™ã€‚ã‚¹ãƒˆãƒ¬ã‚¹ç®¡ç†ã‚„å¿ƒç†çš„å¥åº·ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
}

st.title("ğŸ’¬ HealthX AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")
st.write("""
ã“ã®ã‚¢ãƒ—ãƒªã§ã¯ã€å…¥åŠ›ã—ãŸè³ªå•ã«å¯¾ã—ã¦ã€é¸æŠã—ãŸå°‚é–€å®¶ã®è¦–ç‚¹ã§å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
æ“ä½œæ–¹æ³•:
1. å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚
2. è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚
3. ã€Œé€ä¿¡ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨ã€LLMã‹ã‚‰ã®å›ç­”ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
""")

selected_expert = st.radio("å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸æŠã—ã¦ãã ã•ã„:", list(expert_options.keys()))
user_input = st.text_area("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", placeholder="ä¾‹: å¥åº·çš„ãªæœé£Ÿã®ãƒã‚¤ãƒ³ãƒˆã¯ï¼Ÿ")

def generate_response(question: str, expert_role: str) -> str:
    system_message = SystemMessage(content=expert_role)
    human_message = HumanMessage(content=question)
    response = llm.invoke([system_message, human_message])
    return response.content

if st.button("é€ä¿¡"):
    if user_input.strip():
        with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
            expert_prompt = expert_options[selected_expert]
            answer = generate_response(user_input, expert_prompt)
        st.success("å›ç­”:")
        st.write(answer)
    else:
        st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
